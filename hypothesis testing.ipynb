{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook essentially re-implements some of the examples from Think Stats 2e, by Allen Downey. I've tried to keep the names and the structure as similar as is reasonable, so that these examples can be clearly matched up with the Python examples from the book.\n",
    "\n",
    "A major change is that I don't use an object-oriented approach. From a pedagogical viewpoint, I think this is unfortunate. The abstraction that Allen implements is highly informative. I think it does a better job demonstrating the core elements of hypothesis testing than any other approach I've seen.\n",
    "\n",
    "However, in my limited experience, most people who work in R do not naturally develop in an object-oriented way<sup>1</sup>. So for my first pass here, I went with what I think is most accessible example rather than most elegant. When I'm a better R developer, perhaps I'll change my mind and rewrite it all.\n",
    "\n",
    "<sup>1</sup> *Please correct me on this, if you have reason to believe differently.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test the fairness of a coin\n",
    "\n",
    "If we want to evaluate whether a coin is fair or not, then we can simply compare the number of heads and number of tails that we get from our coin and compare it to the values that we would get from a fair coing. This can be done directly using the binomial distribution, but here we'll actually calculate the p-value using simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of heads and tails\n",
    "h <- 140\n",
    "t <- 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the test statistic, in this case the difference between the number of heads and tails\n",
    "coin_test.statistic  <- function(data) {\n",
    "    heads <- data[1]\n",
    "    tails <- data[2]\n",
    "    test_stat  <- abs(heads - tails)\n",
    "}\n",
    "\n",
    "# and the model for the null hypothesis, \n",
    "# which in this case is simply to \"flip\" a fair coin\n",
    "coin_test.run_model <- function(data) {\n",
    "    n <- data[1] + data[2]\n",
    "    x <- sample(2, n, replace = TRUE)\n",
    "    result <- c(sum(x == 1), sum(x == 2))\n",
    "    return(result)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip the coin n times and see how often the result was\n",
    "# more extreme than our actual data\n",
    "iter  <- 1000\n",
    "\n",
    "actual.data  <- c(h, t)\n",
    "actual.statistic <- coin_test.statistic(actual.data)\n",
    "\n",
    "sim.statistic  <- numeric(iter)\n",
    "for (ii in 1:iter) {\n",
    "    run.data <- coin_test.run_model(actual.data)\n",
    "    sim.statistic[ii] <- coin_test.statistic(run.data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p  <- sum(sim.statistic > actual.statistic) / length(sim.statistic)\n",
    "\n",
    "writeLines(sprintf(\"the p-value is %.2e\", p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test a difference in means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than the National Survey of Family Growth data (NSFG), I'll use a dataset on wine quality from Kaggle. You can download it from [here](https://www.kaggle.com/zynicide/wine-reviews). The methodology remains the same as in Think Stats, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(readr)\n",
    "tb.red  <- read_delim(\"data//winequality-red.csv\", delim = \";\")\n",
    "tb.white <- read_delim(\"data//winequality-white.csv\", delim = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_means_permute.statistic <- function(data) {\n",
    "    group.1 <- data[[1]]\n",
    "    group.2 <- data[[2]]\n",
    "    \n",
    "    test.statistic  <- abs(mean(group.1) - mean(group.2))\n",
    "    return(test.statistic)\n",
    "}\n",
    "\n",
    "diff_means_permute.run_model <- function(data) {\n",
    "    group.1 <- data[[1]]\n",
    "    group.2 <- data[[2]]\n",
    "    \n",
    "    pool <- c(group.1, group.2)\n",
    "    \n",
    "    n1  <- length(group.1)\n",
    "    x  <- sample(pool)\n",
    "    \n",
    "    return(list(x[1:n1], x[(n1+1):length(x)]))\n",
    "}\n",
    "\n",
    "diff_means_permute.pvalue <- function(actual.data, iter = 1000) {\n",
    "    actual.statistic <- diff_means_permute.statistic(actual.data)\n",
    "\n",
    "    sim.statistic  <- numeric(iter)\n",
    "    for (ii in 1:iter) {\n",
    "        run.data <- diff_means_permute.run_model(actual.data)\n",
    "        sim.statistic[ii] <- diff_means_permute.statistic(run.data)\n",
    "    }\n",
    "\n",
    "    p  <- sum(sim.statistic > actual.statistic) / length(sim.statistic)\n",
    "    return(p)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permute the means to create random groups,\n",
    "# compare simulated means to actual to get p-value\n",
    "\n",
    "pvalue <- diff_means_permute.pvalue(list(tb.red$alcohol, tb.white$alcohol), iter = 1000)\n",
    "\n",
    "writeLines(sprintf(\"the p-value is %.3e\", pvalue))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
